{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itz-abhay/Hospital-Cost-Prediction/blob/main/Hospital_cost_prediction_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Verify A\n",
        "\n"
      ],
      "metadata": {
        "id": "1ua4ODv-FF6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "def verify_part_a():\n",
        "    \"\"\"\n",
        "    Verifying results of Part a.\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the predicted and actual weights, output files.\n",
        "    actual_output = np.loadtxt(\"/content/model_outputfile_a.txt\")\n",
        "    actual_weights = np.loadtxt(\"/content/model_weightfile_a.txt\")\n",
        "    predicted_output = np.loadtxt(\"/content/Part_a/predictions.txt\")\n",
        "    predicted_weights = np.loadtxt(\"/content/Part_a/weights.txt\")\n",
        "\n",
        "    if (actual_output.shape[0] != predicted_output.shape[0]):\n",
        "        print(colored(\"Prediction file of wrong dimensions for part a\", \"red\"))\n",
        "        exit()\n",
        "    if (actual_weights.shape[0] != predicted_weights.shape[0]):\n",
        "        print(colored(\"Weight file of wrong dimensions for part a\", \"red\"))\n",
        "        exit()\n",
        "\n",
        "    pred_error = np.sum(np.square(predicted_output - actual_output)) / np.sum(\n",
        "        np.square(actual_output))  # Error in output\n",
        "    weight_error = np.sum(np.square(predicted_weights - actual_weights)) / np.sum(\n",
        "        np.square(actual_weights))  # Error in weights\n",
        "\n",
        "    print(colored(\"Error in Predictions for part a : \" + str(pred_error), \"green\"))\n",
        "    print(colored(\"Error in Weights for part a : \" + str(weight_error), \"green\"))"
      ],
      "metadata": {
        "id": "IPlT-PkyFEih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify B"
      ],
      "metadata": {
        "id": "uAL_F6ZmFI2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "def verify_part_b():\n",
        "    \"\"\"\n",
        "    Verifying results of Part b.\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the predicted and actual weights, output files.\n",
        "    actual_output = np.loadtxt(\"/content/model_outputfile_b.txt\")\n",
        "    actual_weights = np.loadtxt(\"/content/model_weightfile_b.txt\")\n",
        "    predicted_output = np.loadtxt(\"/content/Part_b/predictions.txt\")\n",
        "    predicted_weights = np.loadtxt(\"/content/Part_b/weights.txt\")\n",
        "\n",
        "    if (actual_output.shape[0] != predicted_output.shape[0]):\n",
        "        print(colored(\"Prediction file of wrong dimensions for part b\", \"red\"))\n",
        "        exit()\n",
        "    if (actual_weights.shape[0] != predicted_weights.shape[0]):\n",
        "        print(colored(\"Weight file of wrong dimensions for part b\", \"red\"))\n",
        "        exit()\n",
        "\n",
        "    pred_error = np.sum(np.square(predicted_output - actual_output)) / np.sum(\n",
        "        np.square(actual_output))  # Error in output\n",
        "    weight_error = np.sum(np.square(predicted_weights - actual_weights)) / np.sum(\n",
        "        np.square(actual_weights))  # Error in weights\n",
        "\n",
        "    print(colored(\"Error in Predictions for part b : \" + str(pred_error), \"green\"))\n",
        "    print(colored(\"Error in Weights for part b : \" + str(weight_error), \"green\"))"
      ],
      "metadata": {
        "id": "DQJgXcMxFKZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross Validation"
      ],
      "metadata": {
        "id": "LBYpLcaKEcv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voc_ev5JEaf2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "def KFoldCrossValidation(X_train, Y_train, model, k=10):\n",
        "    \"\"\"\n",
        "    Do k-fold cross validation using the model. The score function of k-fold CV is R2 Score.\n",
        "    :param X_train: Training data\n",
        "    :param Y_train: Test data\n",
        "    :param model: model to be used for learning weights of features\n",
        "    :param k: k of k-fold cross CV\n",
        "    :return: k-fold CV R2 Score\n",
        "    \"\"\"\n",
        "    r = int(X_train.shape[0] / k)\n",
        "    k_fold_r2_score = 0.0\n",
        "    fold = 1\n",
        "    while (fold <= k):\n",
        "        X1 = X_train[0:(fold - 1) * r]\n",
        "        Y1 = Y_train[0:(fold - 1) * r]\n",
        "        X2 = X_train[(fold - 1) * r:fold * r]\n",
        "        Y2 = Y_train[(fold - 1) * r:fold * r]\n",
        "        X3 = X_train[fold * r:(fold + 1) * r]\n",
        "        Y3 = Y_train[fold * r:(fold + 1) * r]\n",
        "\n",
        "        X_tra = np.concatenate((X1, X3), axis=0)\n",
        "        Y_tra = np.concatenate((Y1, Y3), axis=0)\n",
        "\n",
        "        model.fit(X_tra, Y_tra)\n",
        "        predictions = model.predict(X2)\n",
        "        k_fold_r2_score += r2_score(Y2, predictions)\n",
        "        fold += 1\n",
        "\n",
        "    k_fold_r2_score /= k\n",
        "    return k_fold_r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part A"
      ],
      "metadata": {
        "id": "VFUJ_r8LEk0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def solve_a(X_train, Y_train, X_test, results_path):\n",
        "    \"\"\"\n",
        "    Do Part a i.e. use linear regression to predict total costs.\n",
        "    :param X_train: Training data\n",
        "    :param Y_train: Training labels\n",
        "    :param X_test: Test data\n",
        "    :param results_path: Path to store the results\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train,Y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    weights = model.coef_  # weights of the features\n",
        "\n",
        "    results_path = os.path.join(results_path, \"Part_a\")\n",
        "    try:\n",
        "        os.mkdir(results_path)\n",
        "    except:\n",
        "        do_nothing = True\n",
        "\n",
        "    np.savetxt(os.path.join(results_path, \"weights.txt\"), weights)\n",
        "    np.savetxt(os.path.join(results_path, 'predictions.txt'), prediction)"
      ],
      "metadata": {
        "id": "4NjqP8k6Ef7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part B"
      ],
      "metadata": {
        "id": "fJYDrzS-EqGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# from src.CrossValidation import KFoldCrossValidation\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "def solve_b(X_train, Y_train, X_test, results_path, regc, k):\n",
        "    \"\"\"\n",
        "    Do Part b i.e. use ridge regression to predict total costs.\n",
        "    :param X_train: Training data\n",
        "    :param Y_train: Training labels\n",
        "    :param X_test: Test data\n",
        "    :param results_path: Path to save results\n",
        "    :param regc: List storing the regression penalties which will be used in ridge regression\n",
        "    :param k: k of k-fold CV\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    bp = regc[0]  # Best Regression Penalty\n",
        "    best_r2_score = 0  # Best k-fold R2 Score\n",
        "\n",
        "    df_result = pd.DataFrame(columns=['Ridge Penalty', str(k) + ' - fold R2 Score'])\n",
        "    for l in regc:\n",
        "        model = Ridge(alpha=l)\n",
        "        score = KFoldCrossValidation(X_train=X_train, Y_train=Y_train, model=model, k=k)\n",
        "\n",
        "        dic = {'Ridge Penalty': l, str(k) + ' - fold R2 Score': score}\n",
        "        df_result = df_result.append(dic, ignore_index=True)\n",
        "\n",
        "        if score > best_r2_score:\n",
        "            best_r2_score = score\n",
        "            bp = l\n",
        "\n",
        "    model = Ridge(alpha=bp)  # Best Ridge Regression model\n",
        "    model.fit(X_train, Y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    weights = model.coef_  # Weights of features\n",
        "\n",
        "    results_path = os.path.join(results_path, \"Part_b\")\n",
        "    try:\n",
        "        os.mkdir(results_path)\n",
        "    except:\n",
        "        do_nothing = True\n",
        "\n",
        "    np.savetxt(os.path.join(results_path, \"weights.txt\"), weights)\n",
        "    np.savetxt(os.path.join(results_path, \"predictions.txt\"), predictions)\n",
        "    df_result.to_csv(os.path.join(results_path, \"results_ridge_penalty.csv\"), index=False)"
      ],
      "metadata": {
        "id": "ximPJejBEnYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Enginnering"
      ],
      "metadata": {
        "id": "Dy0qNj6IE4Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def onehotencoding(data, feature_name, target_feature, high_freq_features):\n",
        "    \"\"\"\n",
        "    Do one hot encoding of the feature = feature_name\n",
        "    :param data: data including both train and test data\n",
        "    :param feature_name: name of the feature to be one hot encoded\n",
        "    :param target_feature: target feature to be used in one-hot encoding\n",
        "    :param high_freq_features: features having high unique values\n",
        "    :return: one hot encoded data\n",
        "    \"\"\"\n",
        "    unique_list = data[feature_name].value_counts(sort=True, ascending=False).index\n",
        "    n_arr = np.asarray(data[feature_name].values)\n",
        "    target_arr = np.asarray(data[target_feature].values)\n",
        "    for idx, value in enumerate(unique_list):\n",
        "        data[feature_name + '_' + str(idx)] = np.where(n_arr == value, target_arr, 0)\n",
        "        if idx >= 20 and feature_name in high_freq_features:\n",
        "            # Get one hot encoding of best 20 values only\n",
        "            break\n",
        "    return data\n",
        "\n",
        "\n",
        "def multifeature_onehotencoding(data, feature_name1, feature_name2, target_feature):\n",
        "    \"\"\"\n",
        "    Do multi feature one hot encoding of 2 features feature_name1 and feature_name2\n",
        "    :param data: Data including both training and test data\n",
        "    :param feature_name1: First feature to be used in one hot encoding\n",
        "    :param feature_name2: Second feature to be used in one hot encoding\n",
        "    :param target_feature: target feature to be used in one hot encoding\n",
        "    :return: one hot encoded data\n",
        "    \"\"\"\n",
        "\n",
        "    unique_list1 = data[feature_name1].value_counts(sort=True, ascending=False).index\n",
        "    n_arr1 = np.asarray(data[feature_name1].values)\n",
        "    unique_list2 = data[feature_name2].value_counts(sort=True, ascending=False).index\n",
        "    n_arr2 = np.asarray(data[feature_name2].values)\n",
        "    target_arr = np.asarray(data[target_feature].values)\n",
        "    cnt = 0\n",
        "    for idx1, value1 in enumerate(unique_list1):\n",
        "        for idx2, value2 in enumerate(unique_list2):\n",
        "            data[feature_name1 + '_' + feature_name2 + '_' + str(cnt)] = np.where(\n",
        "                (n_arr1 == value1) & ((n_arr2 == value2)), target_arr, 0)\n",
        "            cnt += 1\n",
        "    return data\n",
        "\n",
        "\n",
        "def feature_engineering(data):\n",
        "    \"\"\"\n",
        "    Do feature engineering on the data.\n",
        "    :param data: DataFrame storing training and test data\n",
        "    :return: data after feature engineering\n",
        "    \"\"\"\n",
        "\n",
        "    # Features to one hot encode\n",
        "    features_to_one_hot_encode = ['Ethnicity', 'Type of Admission', 'Age Group', 'Operating Certificate Number',\n",
        "                                  'Payment Typology 1', 'APR Severity of Illness Description',\n",
        "                                  'APR Risk of Mortality', 'APR Medical Surgical Description',\n",
        "                                  'APR MDC Description', 'CCS Procedure Description',\n",
        "                                  'CCS Diagnosis Description', 'APR DRG Description']\n",
        "\n",
        "    # High Frequency features\n",
        "    high_frequency_features = ['CCS Procedure Description', 'CCS Diagnosis Description', 'APR DRG Description']\n",
        "\n",
        "    for feature_name in features_to_one_hot_encode:\n",
        "        data = onehotencoding(data=data, feature_name=feature_name, target_feature='Length of Stay',\n",
        "                              high_freq_features=high_frequency_features)\n",
        "\n",
        "    # Features to multi one hot encode\n",
        "    multi_features_to_one_hot_encode = [('Health Service Area', 'Emergency Department Indicator'),\n",
        "                                        ('Age Group', 'Emergency Department Indicator')]\n",
        "\n",
        "    for feature_name1, feature_name2 in multi_features_to_one_hot_encode:\n",
        "        data = multifeature_onehotencoding(data, feature_name1, feature_name2, target_feature='Length of Stay')\n",
        "\n",
        "    # Features to drop\n",
        "    features_to_drop = ['Ethnicity', 'Type of Admission', 'Age Group', 'Operating Certificate Number',\n",
        "                        'Payment Typology 1', 'APR Severity of Illness Description',\n",
        "                        'APR Risk of Mortality', 'APR Medical Surgical Description',\n",
        "                        'Race', 'Gender', 'Facility Id', 'CCS Diagnosis Code', 'CCS Procedure Code', 'APR DRG Code',\n",
        "                        'APR MDC Code']\n",
        "\n",
        "    data.drop(features_to_drop, inplace=True, axis=1)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "lYvjJN7lE6tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part C"
      ],
      "metadata": {
        "id": "15IYTR69EvA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "# from src.CrossValidation import KFoldCrossValidation\n",
        "# from src.feature_engineering import feature_engineering\n",
        "# from src.models.LassoRegression import LassoRegression\n",
        "# from src.models.RidgeRegression import RidgeRegression\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "\n",
        "\n",
        "def plots(predictions, actual, results_path, LOS):\n",
        "    \"\"\"\n",
        "    Make plots\n",
        "    :param predictions: Predicted values\n",
        "    :param actual: Actual values\n",
        "    :param results_path: Path to store the results\n",
        "    :param LOS: Length of Stay training data\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    residuals = predictions - actual\n",
        "\n",
        "    results_path = os.path.join(results_path, 'Plots')\n",
        "    try:\n",
        "        os.mkdir(results_path)\n",
        "    except:\n",
        "        do_nothing = True\n",
        "\n",
        "    # Create Total Costs vs LOS plot\n",
        "    plt.scatter(LOS, actual, s=1)\n",
        "    plt.title('Total Costs vs Length of Stay')\n",
        "    plt.xlabel('Length of Stay')\n",
        "    plt.ylabel('Total Costs')\n",
        "    plt.savefig(os.path.join(results_path, 'TotalCostsVsLOS.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # Create Predicted Total Costs vs Actual Total Costs plot\n",
        "    val = np.polyfit(x=actual, y=predictions, deg=1)\n",
        "    m = val[0]\n",
        "    b = val[1]\n",
        "    plt.scatter(actual, predictions, s=1)\n",
        "    plt.plot(actual, m * actual + b, c='k')  # Best fit line\n",
        "    plt.title('Predictions vs Actual')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predictions')\n",
        "    plt.savefig(os.path.join(results_path, 'PredictionsVsActual.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # Create residuals vs Actual Total Costs plot\n",
        "    plt.scatter(actual, residuals, s=1)\n",
        "    plt.title('Residuals vs Actual')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.savefig(os.path.join(results_path, 'ResidualsVsActual.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # Create histogram plot of residuals\n",
        "    plt.hist(residuals, bins=1000, range=(-1e5, 1e5))\n",
        "    plt.title('Density Plot of Residuals')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Residuals')\n",
        "    plt.savefig(os.path.join(results_path, 'Histogram.png'))\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "def use_correlation(X_train, Y_train, X_test):\n",
        "    \"\"\"\n",
        "    Find the best power p of a feature so that power(feature,p) and Y_train have high absolute value of correlation.\n",
        "    :param X_train: Training data\n",
        "    :param Y_train: Training labels\n",
        "    :param X_test: Test data\n",
        "    :return: X_train and X_test with updated values\n",
        "    \"\"\"\n",
        "\n",
        "    for idx in range(X_train.shape[1]):\n",
        "        p = 0.1\n",
        "        max_corr = 0\n",
        "        best_p = 0.1\n",
        "        while (p <= 1.5):\n",
        "            corr = abs(np.corrcoef(Y_train, np.power(X_train[:, idx], p))[0][1])\n",
        "            if corr > max_corr:\n",
        "                max_corr = corr\n",
        "                best_p = p\n",
        "            p += 0.1\n",
        "        X_train[:, idx] = np.power(X_train[:, idx], best_p)\n",
        "        X_test[:, idx] = np.power(X_test[:, idx], best_p)\n",
        "\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def solve_c(train_data, test_data, results_path, k, get_features_importance, reg_lower_limit, reg_upper_limit,\n",
        "            random_searches):\n",
        "    \"\"\"\n",
        "    Do part c i.e. use feature engineering to improve model performance.\n",
        "    :param train_data: Training data\n",
        "    :param test_data: Test data\n",
        "    :param results_path: Path to store the results\n",
        "    :param k: k of k-fold CV\n",
        "    :param get_important_features: Whether to get important features or not using Lasso Regression\n",
        "    :param reg_lower_limit: Lower limit of regularisation penalty\n",
        "    :param reg_upper_limit: Upper limit of regularisation penalty\n",
        "    :param random_searches: Number of random searches in [reg_lower_limit,reg_upper_limit] to find the\n",
        "                            best regularisation penalty\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    X_train = train_data.iloc[:, 1:-1]\n",
        "    Y_train = np.asarray(train_data['Total Costs'].values)\n",
        "    X_test = test_data.iloc[:, 1:-1]\n",
        "\n",
        "    col = np.ones(X_train.shape[0])\n",
        "    X_train['bias'] = col\n",
        "    col = np.ones(X_test.shape[0])\n",
        "    X_test['bias'] = col\n",
        "\n",
        "    model = Ridge(alpha=0.001)\n",
        "    without_feature_engineering_k_fold_r2_score = KFoldCrossValidation(X_train=np.asarray(X_train),\n",
        "                                                                       Y_train=Y_train, model=model, k=k)\n",
        "\n",
        "    print(colored(str(k) + '-Fold R2 Score (Without Feature Engineering) : ' +\n",
        "                  str(without_feature_engineering_k_fold_r2_score), 'cyan'))\n",
        "\n",
        "    print(colored('Feature Engineering started ...', 'cyan'))\n",
        "    # Remove outliers\n",
        "    non_outliers = (Y_train <= 2e5)\n",
        "    Y_train = Y_train[non_outliers]\n",
        "    X_train = X_train.loc[non_outliers]\n",
        "\n",
        "    data = pd.concat([X_train, X_test], axis=0)\n",
        "\n",
        "    # Feature Engineering\n",
        "    data = feature_engineering(data=data)\n",
        "\n",
        "    index_bias = list(data.columns).index('bias')  # Index of bias in features list\n",
        "\n",
        "    X_train = np.asarray(data.iloc[0:X_train.shape[0]])\n",
        "    X_test = np.asarray(data.iloc[X_train.shape[0]:])\n",
        "\n",
        "    X_train, X_test = use_correlation(X_train=X_train, Y_train=Y_train, X_test=X_test)\n",
        "\n",
        "    print(colored('Finished Feature Engineering', 'cyan'))\n",
        "\n",
        "    print(colored('\\nFinding best regularisation penalty started ...', 'cyan'))\n",
        "\n",
        "    best_r2_score = 0  # Best k-fold R2 score\n",
        "    bp = 0  # Best Ridge Regression Penalty\n",
        "    df_result = pd.DataFrame(columns=['Ridge Penalty', str(k) + ' - fold R2 Score'])\n",
        "    for idx in range(random_searches):\n",
        "        l = random.uniform(reg_lower_limit, reg_upper_limit)\n",
        "        model = Ridge(alpha=l)\n",
        "        score = KFoldCrossValidation(X_train=X_train, Y_train=Y_train, model=model, k=k)\n",
        "\n",
        "        dic = {'Ridge Penalty': l, str(k) + ' - fold R2 Score': score}\n",
        "        df_result = df_result.append(dic, ignore_index=True)\n",
        "\n",
        "        if score > best_r2_score:\n",
        "            best_r2_score = score\n",
        "            bp = l\n",
        "\n",
        "    print(colored('Best ' + str(k) + '-Fold R2 Score after feature engineering : ' + str(best_r2_score), 'cyan'))\n",
        "\n",
        "    improvemet_r2_score = (best_r2_score - without_feature_engineering_k_fold_r2_score) * 100\n",
        "    improvemet_r2_score /= without_feature_engineering_k_fold_r2_score\n",
        "    improvemet_r2_score = round(improvemet_r2_score, 2)\n",
        "\n",
        "    print(colored('Improvement in ' + str(k) + ' - Fold R2 Score due to feature engineering : '\n",
        "                  + str(improvemet_r2_score) + ' %', 'cyan'))\n",
        "\n",
        "    model = Ridge(alpha=bp)\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    X_test = pd.DataFrame(X_test)\n",
        "    X_test.fillna(value=0, inplace=True) #Make sure there are no missing values in X_test\n",
        "    predictions = model.predict(X_test)\n",
        "    weights = model.coef_\n",
        "\n",
        "    results_path = os.path.join(results_path, \"Part_c\")\n",
        "    try:\n",
        "        os.mkdir(results_path)\n",
        "    except:\n",
        "        do_nothing = True\n",
        "\n",
        "    np.savetxt(os.path.join(results_path, \"weights.txt\"), weights)\n",
        "    np.savetxt(os.path.join(results_path, \"predictions.txt\"), predictions)\n",
        "    df_result.to_csv(os.path.join(results_path, \"results_ridge_penalty.csv\"), index=False)\n",
        "\n",
        "    train_predictions = model.predict(X_train)\n",
        "\n",
        "    plots(predictions=train_predictions, actual=Y_train,\n",
        "          results_path=results_path,\n",
        "          LOS=data['Length of Stay'][0:X_train.shape[0]].values)\n",
        "\n",
        "    if get_features_importance:\n",
        "        # Use Lasso Regression to get feature importance\n",
        "        print(colored('Calculating Importance of features ...', 'cyan'))\n",
        "        model = Lasso(alpha=bp)\n",
        "        model.fit(X_train, Y_train)\n",
        "        weights = model.coef_\n",
        "        features_importance = []\n",
        "        correlation = []\n",
        "        feature_names = data.columns\n",
        "        for idx, coef in enumerate(weights):\n",
        "            importance = abs(coef) * np.mean(X_train[:, idx])  # Importance of that feature\n",
        "            features_importance.append((feature_names[idx], importance))\n",
        "\n",
        "        for idx in range(X_train.shape[1]):\n",
        "            corr = abs(np.corrcoef(Y_train, X_train[:, idx])[0][1])\n",
        "            if math.isnan(corr) is False:\n",
        "                correlation.append((feature_names[idx], corr))\n",
        "\n",
        "        features_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "        correlation.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        with open(os.path.join(results_path, \"features_importance.txt\"), 'w') as f:\n",
        "            f.write('Feature importance from highest to lowest : ' + '\\n')\n",
        "            f.write('\\n')\n",
        "            idx = 1\n",
        "            for feature, importance in features_importance:\n",
        "                f.write(str(idx) + '. ' + feature + ' : ' + str(importance) + '\\n')\n",
        "                idx += 1\n",
        "\n",
        "        with open(os.path.join(results_path, \"correlation.txt\"), 'w') as f:\n",
        "            f.write('Correlation between features and Total Costs from highest to lowest : ' + '\\n')\n",
        "            f.write('\\n')\n",
        "            idx = 1\n",
        "            for feature, corr in correlation:\n",
        "                f.write(str(idx) + '. ' + feature + ' : ' + str(corr) + '\\n')\n",
        "                idx += 1\n",
        "\n",
        "        print(colored('Importance of features calculated', 'cyan'))"
      ],
      "metadata": {
        "id": "MyIh-KOeEsDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run"
      ],
      "metadata": {
        "id": "6Xn6zVd8FTEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.system('color')\n",
        "# Read Parameters.yml file\n",
        "with open(\"Parameters.yml\", 'r') as stream:\n",
        "    dic = yaml.safe_load(stream)\n",
        "\n",
        "# Get training and test data\n",
        "train_data = pd.read_csv(dic['train_data'])\n",
        "test_data = pd.read_csv(dic['test_data'])\n",
        "\n",
        "# Total Costs is the last column of training and test data\n",
        "Y_train = np.asarray(train_data['Total Costs'])\n",
        "X_train = np.asarray(train_data.iloc[:, 1:-1])\n",
        "X_test = np.asarray(test_data.iloc[:, 1:])\n",
        "\n",
        "# Adding column of ones to handle the bias\n",
        "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "regc = dic['regularisation_penalty']\n",
        "results_path = dic['results_path']\n",
        "k = dic['k']\n",
        "get_features_importance = dic['get_features_importance']\n",
        "verify_res = dic['verify_results']\n",
        "reg_lower_limit = dic['regularisation_penalty_lower_limit']\n",
        "reg_upper_limit = dic['regularisation_penalty_upper_limit']\n",
        "random_searches = dic['random_searches']\n",
        "\n",
        "if \"a\" in dic['parts']:\n",
        "    # Do Part a : Use Linear Regression to predict Total Costs\n",
        "    start = time.time()\n",
        "    print(colored('Part a started ... ', 'magenta'))\n",
        "    solve_a(X_train=X_train, Y_train=Y_train, X_test=X_test, results_path=results_path)\n",
        "    if verify_res:\n",
        "        verify_part_a()\n",
        "    end = time.time()\n",
        "    print(colored('Part a finished (' + str(round(end - start, 2)) + ' s)', 'magenta'))\n",
        "\n",
        "if \"b\" in dic['parts']:\n",
        "    # Do Part b : Use Ridge Regression to predict Total Costs\n",
        "    start = time.time()\n",
        "    print(colored('\\n\\nPart b started ... ', 'magenta'))\n",
        "    solve_b(X_train=X_train, Y_train=Y_train, X_test=X_test, results_path=results_path, regc=regc, k=k)\n",
        "    if verify_res:\n",
        "        verify_part_b()\n",
        "    end = time.time()\n",
        "    print(colored('Part b finished (' + str(round(end - start, 2)) + ' s)', 'magenta'))\n",
        "\n",
        "if \"c\" in dic['parts']:\n",
        "    # Do Part c : Use Feature Engineering to improve R2 Score\n",
        "    start = time.time()\n",
        "    print(colored('\\n\\nPart c started ... ', 'magenta'))\n",
        "    solve_c(train_data=train_data, test_data=test_data, results_path=results_path, k=k,\n",
        "            get_features_importance=get_features_importance, reg_lower_limit=reg_lower_limit,\n",
        "            reg_upper_limit=reg_upper_limit, random_searches=random_searches)\n",
        "    end = time.time()\n",
        "    print(colored('Part c finished (' + str(round(end - start, 2)) + ' s)', 'magenta'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "sGxmvPicFULm",
        "outputId": "249dfee5-fd77-4fc3-a4e2-691dca7b53a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part a started ... \n",
            "Error in Predictions for part a : 2.0414601545564422e-23\n",
            "Error in Weights for part a : 0.09146520729281783\n",
            "Part a finished (3.15 s)\n",
            "\n",
            "\n",
            "Part b started ... \n",
            "Error in Predictions for part b : 5.910963915400773e-17\n",
            "Error in Weights for part b : 0.09146533372437309\n",
            "Part b finished (18.06 s)\n",
            "\n",
            "\n",
            "Part c started ... \n",
            "10-Fold R2 Score (Without Feature Engineering) : 0.5607403445822712\n",
            "Feature Engineering started ...\n",
            "Finished Feature Engineering\n",
            "\n",
            "Finding best regularisation penalty started ...\n",
            "Best 10-Fold R2 Score after feature engineering : 0.7780019182825523\n",
            "Improvement in 10 - Fold R2 Score due to feature engineering : 38.75 %\n",
            "Calculating Importance of features ...\n",
            "Importance of features calculated\n",
            "Part c finished (689.61 s)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}